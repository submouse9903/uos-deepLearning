{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/submouse9903/uos-deepLearning/blob/main/CH05_RNN(Teacher_forcing).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNsFtdYqgr2o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFsapppekmIb"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(1)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCsnX3aMgy9h"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv('http://ranking.uos.ac.kr/class/RB/stock_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDln0vxqjI9X"
      },
      "outputs": [],
      "source": [
        "x_0 = np.array(df['Close'][0:-1])\n",
        "x_1 = np.array(df['Close'][1:])\n",
        "x = np.log(1-(x_1-x_0)/x_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YbM7CAXg4gh"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters\n",
        "seq_len = 6\n",
        "hidden_size = 5\n",
        "num_layers = 1\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### encoder와 학습용 decoder, 추론용 decoder \n",
        "- encoder: 입력열 데이터를 받아서 hidden feature 를 출력으로 주는 함수\n",
        "   + 모형구조: rnn 으로 구성하고 h를 마지막 출력한다.  \n",
        "- 학습용 decoder: (실제) 출력열 데이터를 받아 예측값을 만들어 내는 decoder \n",
        "  + 모형구조: rnn으로 구성하고 입력을 encoder 의 h와 response variable 인 출력열을 받는다. (Teacher forcing method)\n",
        "- 추론용 decoder: 예측된 출력열 데이터를 받아 순차적으로 예측값을 만들어 내는 decoder \n",
        "  + 모형구조: for 문을 이용하한 재귀함수로 작성한다. 1) rnn 을 사용하며 첫번째 step 의 rnn cell은 h를 받고 $\\hat y$ (출력값)과 $h$를 반환한다. 3) 반복문을 통해 다음 rnn cell의 계산에서는 직전에 계산된 $\\hat y$ (출력값)과 $h$를 입력값으로 받아 출력값을 만든다. \n",
        "  (첫번째 추론용 decoder의 입력변수는 $0$을 사용하기로 하자.)\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u7hgvti4SaoO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_cH8BVYkEFn"
      },
      "outputs": [],
      "source": [
        "# Define the encoder\n",
        "class myEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(myEncoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]\n",
        "        out = out.reshape(self.num_layers, x.size(0), self.hidden_size)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(참고) myEncoder 의 forward 마지막 줄의 \n",
        "> out = out.reshape(self.num_layers, x.size(0), self.hidden_size) \n",
        "부분은 out 이 다음 Decoder의 h0로 들어가기 때문에 shape를 맞춰준 것임. \n",
        "\n",
        "> (num_layers, x.size(0), self.hidden_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZpI8O7h8tHat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73N0LSAFKUnA",
        "outputId": "b0e36531-84ab-4cc5-8f32-d2f2e9160b9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00430734,  0.00471075,  0.00626551, -0.00179657,  0.00147374,\n",
              "        0.00677598,  0.00503846,  0.00145651,  0.00174275,  0.00695242,\n",
              "       -0.00018716,  0.00368627])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "x[0:12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d62DEiT7KEhI"
      },
      "outputs": [],
      "source": [
        "# window size 설정\n",
        "input_window_size = 6\n",
        "output_window_size = 3\n",
        "# 입력 시퀀스와 출력 시퀀스 정의\n",
        "def create_inout_sequences(input_data, input_window_size, output_window_size):\n",
        "    inout_seq = []\n",
        "    L = len(input_data)\n",
        "    s1 = input_window_size\n",
        "    s2 = output_window_size\n",
        "    for i in range(L - s1 - s2):\n",
        "        train_seq = input_data[i:(i+s1)].reshape(s1,1)\n",
        "        train_seq = train_seq.astype(np.float32)\n",
        "        # teacher forcing\n",
        "        train_seq2 = input_data[(i+s1-1):(i+s1+s2-1)].reshape(s2,1)\n",
        "        train_seq2 = train_seq2.astype(np.float32)\n",
        "        # label\n",
        "        train_label = input_data[(i+s1):(i+s1+s2)].reshape(s2,1)\n",
        "        train_label = train_label.astype(np.float32)\n",
        "        inout_seq.append((train_seq ,train_seq2, train_label))\n",
        "    return inout_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TVWuToSKnE5",
        "outputId": "5a272a3c-cc02-4281-ddb8-8c59d10ba3ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: (6, 1)\n",
            "input for teacher forcing: (3, 1)\n",
            "output: (3, 1)\n",
            "train_data: 722\n"
          ]
        }
      ],
      "source": [
        "# 입력 시퀀스와 출력 시퀀스 생성\n",
        "train_data = create_inout_sequences(x, input_window_size, output_window_size)\n",
        "print('input:', train_data[0][0].shape)\n",
        "print('input for teacher forcing:', train_data[0][1].shape)\n",
        "print('output:', train_data[0][2].shape)\n",
        "print('train_data:', len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WtsfVWFLIwv",
        "outputId": "9bef88c2-cc19-4459-a1e9-6fbfb1ab0549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0:\n",
            "input seq torch.Size([2, 6, 1])\n",
            "input seq for teacher forcing torch.Size([2, 3, 1])\n",
            "output torch.Size([2, 3, 1])\n"
          ]
        }
      ],
      "source": [
        "# 데이터를 batch 단위로 나누기\n",
        "batch_size = 2\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "# batch 단위로 데이터 출력\n",
        "for i, (inputs, inputs2, labels) in enumerate(train_loader):\n",
        "    print(f'Batch {i}:')\n",
        "    #print('Inputs: \\n', inputs)\n",
        "    print(\"input seq\",inputs.shape)\n",
        "    print(\"input seq for teacher forcing\",inputs2.shape)\n",
        "    #print('Labels: \\n', labels)\n",
        "    print(\"output\",labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder\n",
        "class myDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(myDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        \n",
        "    def forward(self, h, x):\n",
        "        out, _ = self.rnn(x, h)\n",
        "        return out"
      ],
      "metadata": {
        "id": "urat1iKvmRD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder Test 해보기\n",
        "- encoder가 출력값을 올바르게 주는지 확인하기"
      ],
      "metadata": {
        "id": "Yuk9Bzdhs2b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = myEncoder(input_size=1, hidden_size=5, num_layers=1).to(device)\n",
        "for inputs, inputs2, labels in train_loader:\n",
        "  input = inputs.to(device)\n",
        "  h = encoder(input)\n",
        "  print(h)\n",
        "  print(h.shape)\n",
        "  break "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeunL5KUnve6",
        "outputId": "121262ca-5a91-4514-c3b2-1c607bda08c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.3743, -0.1064, -0.7296,  0.3904,  0.3075],\n",
            "         [ 0.3746, -0.1070, -0.7291,  0.3899,  0.3068]]], device='cuda:0',\n",
            "       grad_fn=<ReshapeAliasBackward0>)\n",
            "torch.Size([1, 2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder Test 해 보기\n",
        "- decoder 가 올바른 출력값을 주는지 확인해보기"
      ],
      "metadata": {
        "id": "47ghuc-rtCSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = myDecoder(input_size=1, hidden_size=5, num_layers=1).to(device)\n",
        "for inputs, inputs2, labels in train_loader:\n",
        "  input = inputs.to(device)\n",
        "  input2 = inputs2.to(device)\n",
        "  label = labels.to(device)\n",
        "  h = encoder(input)\n",
        "  print(\"========= Encoder =========\")\n",
        "  print(h)\n",
        "  print(h.shape)\n",
        "  print(\"========= Decoder =========\")\n",
        "  output = decoder(h, input2)\n",
        "  print(output)\n",
        "  print(output.shape)\n",
        "  break "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuSlg-sTpUhz",
        "outputId": "98678dca-e18e-40cf-a69a-14dacad82e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Encoder =========\n",
            "tensor([[[ 0.3743, -0.1064, -0.7296,  0.3904,  0.3075],\n",
            "         [ 0.3746, -0.1070, -0.7291,  0.3899,  0.3068]]], device='cuda:0',\n",
            "       grad_fn=<ReshapeAliasBackward0>)\n",
            "torch.Size([1, 2, 5])\n",
            "========= Decoder =========\n",
            "tensor([[[-0.0730, -0.7599,  0.0499, -0.1443,  0.2752],\n",
            "         [-0.5384, -0.7812,  0.3192, -0.0335,  0.4765],\n",
            "         [-0.6578, -0.6925,  0.2733, -0.0528,  0.4829]],\n",
            "\n",
            "        [[-0.0725, -0.7598,  0.0499, -0.1440,  0.2746],\n",
            "         [-0.5372, -0.7808,  0.3185, -0.0331,  0.4751],\n",
            "         [-0.6576, -0.6925,  0.2735, -0.0530,  0.4827]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward0>)\n",
            "torch.Size([2, 3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder 수정하기 (회귀모형의 출력값을 줄 수 있도록)"
      ],
      "metadata": {
        "id": "VnXXNdp0t9i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder (Teacher forcing)\n",
        "class myDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(myDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size,1)\n",
        "        \n",
        "    def forward(self, h, x):\n",
        "        out, _ = self.rnn(x, h)\n",
        "        predict_output = []\n",
        "        for k in range(x.size(1)):\n",
        "          predict_output.append(self.fc(out[:,k,:]))\n",
        "\n",
        "        predict_output = torch.cat(predict_output, axis = 1)\n",
        "        predict_output = predict_output.reshape(-1,x.size(1),1)\n",
        "        return predict_output"
      ],
      "metadata": {
        "id": "UoNvNnyMuvLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = myDecoder(input_size=1, hidden_size=5, num_layers=1).to(device)\n",
        "for inputs, inputs2, labels in train_loader:\n",
        "  input = inputs.to(device)\n",
        "  input2 = inputs2.to(device)\n",
        "  label = labels.to(device)\n",
        "  h = encoder(input)\n",
        "  print(\"========= Decoder =========\")\n",
        "  output = decoder(h, input2)\n",
        "  print(output)\n",
        "  print(output.shape)\n",
        "  break "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2abKrciWwxFg",
        "outputId": "e918f9aa-41a2-4d4c-9f2f-9101fe574972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Decoder =========\n",
            "tensor([[[ 0.5178],\n",
            "         [ 0.1564],\n",
            "         [-0.0297]],\n",
            "\n",
            "        [[ 0.5177],\n",
            "         [ 0.1564],\n",
            "         [-0.0299]]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "torch.Size([2, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Seq2Seq로 전체 모형 연결하기"
      ],
      "metadata": {
        "id": "-JGmj-LRy_VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "  def forward(seff, input, input2):\n",
        "    h = encoder(input)\n",
        "    output = decoder(h, input2)\n",
        "    return output"
      ],
      "metadata": {
        "id": "ovScZ2Uh4WFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2Seq(encoder, decoder).to(device)"
      ],
      "metadata": {
        "id": "gwS7YiBM8fPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, inputs2, labels in train_loader:\n",
        "  input = inputs.to(device)\n",
        "  input2 = inputs2.to(device)\n",
        "  label = labels.to(device)\n",
        "  print(\"========= Decoder =========\")\n",
        "  output = model(input, input2)\n",
        "  print(output)\n",
        "  print(output.shape)\n",
        "  break "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiz8THIf8nXo",
        "outputId": "9d92e6c9-9be6-4e0e-a541-e3efab8e2809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Decoder =========\n",
            "tensor([[[ 0.5178],\n",
            "         [ 0.1564],\n",
            "         [-0.0297]],\n",
            "\n",
            "        [[ 0.5177],\n",
            "         [ 0.1564],\n",
            "         [-0.0299]]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "torch.Size([2, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aGeWpyQMddG"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "for i, (inputs, inputs2, labels) in enumerate(train_loader):\n",
        "  input = inputs.to(device)\n",
        "  input2 = inputs2.to(device)\n",
        "  label = labels.to(device)\n",
        "  output = model(input, input2)\n",
        "  loss = criterion(output, label)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNBDo0Cmy-rp",
        "outputId": "643908bf-7aaa-4614-a78c-f79e3168022a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (inputs, inputs2, labels) in enumerate(train_loader):\n",
        "    input = inputs.to(device)\n",
        "    input2 = inputs2.to(device)\n",
        "    label = labels.to(device)\n",
        "    output = model(input, input2)\n",
        "    loss = criterion(output, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5MoCJayzPcZ",
        "outputId": "f1d988b8-b664-40ce-baff-fbba798cf877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input[0])\n",
        "print(input2[0])\n",
        "print(label[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piIMtNkDSnaL",
        "outputId": "da4b1e69-2c92-4a0e-ccc2-bccc75e7aebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0197],\n",
            "        [-0.0438],\n",
            "        [ 0.0162],\n",
            "        [ 0.0297],\n",
            "        [-0.0093],\n",
            "        [-0.0502]], device='cuda:0')\n",
            "tensor([[-0.0502],\n",
            "        [ 0.0048],\n",
            "        [-0.0003]], device='cuda:0')\n",
            "tensor([[ 0.0048],\n",
            "        [-0.0003],\n",
            "        [ 0.0178]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### - Decoder for Inferece \n",
        "1) encoder 의 마지막 출력값(output)을 받는다. \n",
        "\n",
        "2) 반복문을 통해서 구현한다. \n"
      ],
      "metadata": {
        "id": "pqBxZ5nOHpO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 encoder 가 가지고 있는 parameter를 확인해보자."
      ],
      "metadata": {
        "id": "UNEpSqqHVPn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in decoder.named_children():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m0YDeOPU2eA",
        "outputId": "e5ab2c25-d18f-485f-c79c-c614a2820edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('rnn', RNN(1, 5, batch_first=True))\n",
            "('fc', Linear(in_features=5, out_features=1, bias=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, child in decoder.named_children():\n",
        "  for param in child.parameters():\n",
        "        print(\"#######\", name, '#######')\n",
        "        print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAb5rg7CH4Rt",
        "outputId": "130a2839-ae6d-4754-ea60-50143d661721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####### rnn #######\n",
            "Parameter containing:\n",
            "tensor([[-0.0088],\n",
            "        [ 0.2419],\n",
            "        [-0.0851],\n",
            "        [-0.0805],\n",
            "        [ 0.1123]], device='cuda:0', requires_grad=True)\n",
            "####### rnn #######\n",
            "Parameter containing:\n",
            "tensor([[ 0.0652, -0.1572, -0.0443,  0.2997, -0.1547],\n",
            "        [ 0.1909,  0.2987, -0.2079, -0.4656,  0.3826],\n",
            "        [-0.0635,  0.4770,  0.1646,  0.0788,  0.3076],\n",
            "        [ 0.3685, -0.2228,  0.1145,  0.2716,  0.2860],\n",
            "        [ 0.2492, -0.2832, -0.2326, -0.3760, -0.0085]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "####### rnn #######\n",
            "Parameter containing:\n",
            "tensor([ 0.4378, -0.3405,  0.1624, -0.2911, -0.4540], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "####### rnn #######\n",
            "Parameter containing:\n",
            "tensor([-0.1030,  0.1996,  0.3393, -0.3213,  0.0635], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "####### fc #######\n",
            "Parameter containing:\n",
            "tensor([[0.3251, 0.2477, 0.2367, 0.3446, 0.2930]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "####### fc #######\n",
            "Parameter containing:\n",
            "tensor([0.0746], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = encoder(input)\n",
        "print(\"\",h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAKT5DnVU0Pw",
        "outputId": "8ff5481e-76cb-4e80-8ff3-214120577bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " tensor([[[ 0.1062, -0.0638, -0.4990,  0.2276, -0.0470],\n",
            "         [ 0.1036, -0.0455, -0.5152,  0.2342, -0.0350]]], device='cuda:0',\n",
            "       grad_fn=<ReshapeAliasBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inference = myDecoder(input_size=1, hidden_size=5, num_layers=1).to(device)\n",
        "for name, child in decoder_inference.named_children():\n",
        "  for param in child.parameters():\n",
        "        print(\"#######\", name, '#######')\n",
        "        print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KreyDhBcT00O",
        "outputId": "5321d2f5-1378-4ae2-8eb7-b3b30ac5d6a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####### rnn #######\n",
            "Parameter containing:\n",
            "tensor([[-0.2314],\n",
            "        [ 0.0970],\n",
            "        [-0.1628],\n",
            "        [-0.1005],\n",
            "        [-0.3564]], device='cuda:0', requires_grad=True)\n",
            "####### rnn #######\n",
            "Parameter containing:\n",
            "tensor([[-0.2038, -0.1370,  0.1912,  0.0817,  0.1105],\n",
            "        [ 0.4464,  0.4359,  0.3050,  0.0142, -0.3094],\n",
            "        [ 0.3495, -0.1118, -0.0362, -0.3853, -0.0883],\n",
            "        [-0.2884,  0.4109, -0.3866, -0.3486, -0.0152],\n",
            "        [-0.2418,  0.1600, -0.1721, -0.2101,  0.0253]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "####### rnn #######\n",
            "Parameter containing:\n",
            "tensor([ 0.3237, -0.3146,  0.2100,  0.2873,  0.4375], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "####### rnn #######\n",
            "Parameter containing:\n",
            "tensor([-0.3130,  0.1083, -0.3307,  0.3818, -0.1735], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "####### fc #######\n",
            "Parameter containing:\n",
            "tensor([[ 0.2694,  0.0133, -0.0348, -0.0143,  0.0760]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "####### fc #######\n",
            "Parameter containing:\n",
            "tensor([0.2108], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.rnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H7UjMa_WtY-",
        "outputId": "63ebd506-8c31-47ec-a4d0-ee74587c4ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(1, 5, batch_first=True)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h.shape\n",
        "yhat = input2[:,0:1,:]\n",
        "yhat.shape\n",
        "out, _  = decoder.rnn(yhat, h)\n",
        "out.shape \n",
        "yhat = decoder.fc(out)\n",
        "yhat.shape\n",
        "# repeat \n",
        "h = out.permute(1,0,2)\n",
        "h.shape\n",
        "decoder.rnn(yhat, h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXrs7y-gXPH4",
        "outputId": "d991220e-8461-46d2-d8b9-6aab37452ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.2614, -0.0715,  0.3094, -0.5394, -0.1292]],\n",
              " \n",
              "         [[ 0.2563, -0.0625,  0.3197, -0.5440, -0.1349]]], device='cuda:0',\n",
              "        grad_fn=<CudnnRnnBackward0>),\n",
              " tensor([[[ 0.2614, -0.0715,  0.3094, -0.5394, -0.1292],\n",
              "          [ 0.2563, -0.0625,  0.3197, -0.5440, -0.1349]]], device='cuda:0',\n",
              "        grad_fn=<CudnnRnnBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder (Teacher forcing)\n",
        "class myDecoder_inf(nn.Module):\n",
        "    def __init__(self, decoder):\n",
        "        super(myDecoder_inf, self).__init__()\n",
        "        self.rnn = decoder.rnn\n",
        "        self.fc = decoder.fc\n",
        "        \n",
        "    def forward(self, h, x, output_window_size):\n",
        "        predict_output = []\n",
        "        yhat = x.clone()\n",
        "        for k in range(output_window_size):\n",
        "          out, _ = self.rnn(yhat, h)\n",
        "          yhat = self.fc(out)\n",
        "          h = out.permute(1,0,2)\n",
        "          predict_output.append(yhat)\n",
        "\n",
        "        predict_output = torch.cat(predict_output, axis = 1)\n",
        "        return predict_output"
      ],
      "metadata": {
        "id": "OfsvJ3iJdT85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inf = myDecoder_inf(decoder)"
      ],
      "metadata": {
        "id": "_rKotRSR3E5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = decoder_inf(h,input2[:,0:1,:], output_window_size)\n",
        "out.squeeze(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYjjq-ON3Xnh",
        "outputId": "0076bd21-c7e2-4f19-dc02-96907162e983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0107, -0.0071, -0.0299],\n",
              "        [-0.0084, -0.0085, -0.0326]], device='cuda:0',\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}